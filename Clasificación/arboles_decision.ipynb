{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo Árboles de Decisión\n",
    "\n",
    "A continuación, se dará el código en JupyterNotebook para el algoritmo de clasificación en Árboles de Decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **`pandas (pd)`**: Se utiliza para manipular, analizar y trabajar con DataFrames (estructuras de datos tabulares).\n",
    "- **`numpy (np)`**: Proporciona cómputo numérico eficiente y operaciones con arrays.\n",
    "- **`matplotlib.pyplot (plt)`**: Se usa para visualizaciones (no se usa directamente en este fragmento de código).\n",
    "- **`sklearn.tree.DecisionTreeClassifier`**: Clase para crear y usar clasificadores de árboles de decisión.\n",
    "- **`sklearn.model_selection.train_test_split`**: Divide los datos en conjuntos de entrenamiento y prueba para la evaluación del modelo.\n",
    "- **`sklearn.metrics`**: Proporciona funciones para métricas de evaluación de modelos como la precisión.\n",
    "- **`sklearn.preprocessing`**: Ofrece herramientas para el preprocesamiento de datos, incluida la codificación de etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trabajando con dataset\n",
    "columNames = [\"company\", \"job\", \"degree\", \"salary more than 100k\"]\n",
    "dataset = pd.read_csv(\"salaries.csv\", header = None, names = columNames)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define los nombres de las columnas para el conjunto de datos (\"salarios.csv\").\n",
    "- Lee el archivo CSV usando `pandas.read_csv`, asignando nombres de columna usando `header=None` (sin fila de encabezado) y `names`.\n",
    "- Imprime las primeras filas del conjunto de datos usando `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dataset en caracteristicas (features) y variable destino\n",
    "feature_cols = [\"company\", \"job\", \"degree\"]\n",
    "x = dataset[feature_cols]\n",
    "y = dataset[\"salary more than 100k\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extrae las características (columnas usadas para la predicción) en un DataFrame `x` usando `dataset[feature_cols]`.\n",
    "- Selecciona la variable objetivo (lo que quieres predecir) como `y`, que es la columna \"salary more than 100k\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación de datos categoricos\n",
    "# Label Encoder sabe como entender las etiquetas categoricas\n",
    "labelEncoder = preprocessing.LabelEncoder()\n",
    "# codificando categorias en columnas\n",
    "dataset[\"company\"] = labelEncoder.fit_transform(dataset[\"company\"])\n",
    "dataset[\"job\"] = labelEncoder.fit_transform(dataset[\"job\"])\n",
    "dataset[\"degree\"] = labelEncoder.fit_transform(dataset[\"degree\"])\n",
    "print(dataset.head()) # .head() obtiene las 5 primeras filas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Crea un objeto `LabelEncoder` para manejar datos categóricos.\n",
    "- Codifica las características categóricas (\"company\", \"job\", \"degree\") en valores numéricos adecuados para el algoritmo del árbol de decisión.\n",
    "- El método `fit_transform` aprende las categorías de los datos de entrenamiento y luego transforma los datos.\n",
    "- Imprime las primeras filas después de la codificación para mostrar los cambios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Esta sección utiliza la función `print()` para mostrar dos conjuntos de datos: `x` e `y`.\n",
    "- `x` representa las características del conjunto de datos, que son las variables que se utilizan para predecir la variable objetivo.\n",
    "- `y` representa la variable objetivo, que es lo que se quiere predecir (en este caso, si el salario es superior a 100.000).\n",
    "- Al imprimir estos conjuntos de datos, podemos obtener una idea de su estructura, contenido y distribución de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Esta sección utiliza la función `train_test_split()` de la biblioteca `sklearn.model_selection` para dividir el conjunto de datos en dos subconjuntos: entrenamiento y prueba.\n",
    "- `x_train` y `y_train` representan los subconjuntos de entrenamiento para las características y la variable objetivo, respectivamente.\n",
    "- `x_test` y `y_test` representan los subconjuntos de prueba para las características y la variable objetivo, respectivamente.\n",
    "- El parámetro `test_size` indica la proporción del conjunto de datos que se debe asignar al conjunto de prueba. En este caso, se asigna el 20% (0.2) al conjunto de prueba y el 80% restante al conjunto de entrenamiento.\n",
    "- El parámetro `random_state` se utiliza para garantizar la reproducibilidad de la división de datos. Al establecer una semilla aleatoria, se obtiene la misma división cada vez que se ejecuta el código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear objeto clasificador arbol de decision usando entropia\n",
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 2)\n",
    "\n",
    "# Entrenar clasificador\n",
    "clf_entropy = clf_entropy.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Esta sección crea y entrena un clasificador de árbol de decisión utilizando la biblioteca `sklearn.tree`.\n",
    "- Se crea un objeto `DecisionTreeClassifier` con los siguientes parámetros:\n",
    "    - `criterion`: Especifica el criterio de división del árbol. En este caso, se utiliza la \"entropía\", que mide la incertidumbre en un conjunto de datos.\n",
    "    - `max_depth`: Limita la profundidad máxima del árbol, lo que evita el sobreajuste. En este caso, se establece un límite de 2 niveles.\n",
    "- El método `fit()` se utiliza para entrenar el clasificador utilizando los datos de entrenamiento `x_train` e `y_train`. Esto implica construir el árbol de decisión y aprender las relaciones entre las características y la variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predecir respuesta para dataset test\n",
    "y_pred = clf_entropy.predict(x_test)\n",
    "\n",
    "# imprimir exactitud (accuracy)\n",
    "print(\"Presición:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Esta sección utiliza el clasificador entrenado `clf_entropy` para predecir la variable objetivo para el conjunto de datos de prueba `x_test`.\n",
    "- La función `predict()` toma el conjunto de datos de prueba como entrada y devuelve un vector de predicciones, que representa la variable objetivo predicha para cada punto de datos en `x_test`.\n",
    "- Finalmente, se calcula la precisión del modelo utilizando la función `accuracy_score()` de la biblioteca `sklearn.metrics`. La precisión mide la proporción de predicciones correctas realizadas por el modelo. El resultado se imprime para evaluar el rendimiento del modelo en el conjunto de datos de prueba."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
